{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Top'></a>\n",
    "# <center>Module 2 Lecture Notes: Pandas and Working with Hydrographs</center>\n",
    "\n",
    "<ul>\n",
    "    <li><a href='#Pandas'>Module 2.0. Pandas</a></li>\n",
    "    <li><a href='#Plotting'>Module 2.1. Plotting with Pandas</a></li>\n",
    "    <li><a href='#DateTimes'>Module 2.2. DateTimes</a></li>\n",
    "    <li><a href='#Application'>Module 2.3. Application</a></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Pandas'></a>\n",
    "\n",
    "\n",
    "# Module 2.0 Pandas\n",
    "\n",
    "For the rest of the semester, we are going to start focussing on the tools available to solve the hydrogeologic issues that we discuss in class. Homework 3 (to be assigned next week) will focus on analyzing an aquifer test using Theis Equation and the Jacob Straight Line Method (adopted from a simplified version of Theis).\n",
    "\n",
    "To do this, we need to be able to do three main things in Python:\n",
    "\n",
    "<ul>\n",
    "    <li>Import large datasets</li>\n",
    "    <li>Plot the data</li>\n",
    "    <li>Fit curves to the data</li>\n",
    "</ul>\n",
    "\n",
    "For this, we are going to need to take advantage of the following libraries:\n",
    "\n",
    "<ul>\n",
    "    <li>Pandas Data Analysis Library</li>\n",
    "    <li>SciPy Scientific Computing Library</li>\n",
    "    <li>NumPy Array and Matrix Library</li>\n",
    "    <li>Matplotlib</li>\n",
    "</ul>\n",
    "\n",
    "Let's import the libraries that we are going to use today. We will discuss them further as we introduce them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "import math\n",
    "# import pandas with alias pd\n",
    "import pandas as pd\n",
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Pandas\n",
    "\n",
    "The Python Data Analysis Library, or Pandas, is an open source library providing high-performance, easy-to-use data structures and data analysis tools for Python.\n",
    "\n",
    "https://pandas.pydata.org/\n",
    "\n",
    "<img src = \"https://d1o50x50snmhul.cloudfront.net/wp-content/uploads/2017/06/14111650/00000-00568744-800x533.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Pandas\n",
    "\n",
    "To import Pandas, we type:\n",
    "\n",
    "`import pandas as pd`\n",
    "\n",
    "pd is an alias used by most Python coders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas as an Excel substitute\n",
    "\n",
    "Pandas allows for much of the same functionality as Excel. Pandas has a data type called `DataFrame` that works on the same principle of rows and columns as excel. Each row has an index, and each column has a heading.\n",
    "\n",
    "It is relatively simple to read an Excel file into Python with Pandas using the `pd.read_excel()` function. Similar in functionality, we can also read CSV files using `pd.read_csv()`. The output is a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a csv file from the ISWS website\n",
    "# 'http://aqueduct.isws.illinois.edu/data/381651_HRY-91C_hyd.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, all columns are imported into the DataFrame. If you want to work with a single column within a DataFrame, it is relatively simple using the format `DataFrame.ColumnName` or `DataFrame['ColumnName']`. Even still, the data has an index associated with it. This single set of data is referred to as a Series in Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DataFrame[ColumnName]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working at the ISWS, I have to present information to stakeholders in units of feet. This dataframe makes the mistake of not clearly labeling this. Let's change names of the DataFrame to address this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"A\": [1, 2, 3], \"B\": [4, 5, 6]})\n",
    "print(df)\n",
    "df = df.rename(columns={\"A\": \"a\", \"B\": \"c\"})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change head to head_ft\n",
    "\n",
    "# change depth_to_water_from_land_surface to dtw_ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's do some simple math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the ISWS, we communicate with the public (and need to use feet/inches) and publish international research (where we need to use the metric system). It is critical to be able to do unit conversions, preferably in as few steps as possible.\n",
    "\n",
    "If we were dealing with lists, we can use as a list comprehension, as you say in Module 1. However, with Pandas, it is even easier. You can conduct scalar multiplication on a single column of a DataFrame. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert head_ft and assign to a new column, head_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now you try\n",
    "\n",
    "What is land surface elevation for the well we have been looking at? The calculation is actually easy. The head is the groundwater elevation above mean sea level. The depth to water is the groundwater elevation below land surface. Ergo, land surface elevation is the sum of depth to water and head. You can calculate this is a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try this one on your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Plotting'></a>\n",
    "\n",
    "\n",
    "\n",
    "# Module 2.1 Plotting Data with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next major thing that we want to do is visualize this data in a hydrograph, just like we did with the northeastern Illinois data in Module 1. Plotting data with Pandas is generally easy, let's give it a try!\n",
    "\n",
    "If you took a break after Module 2.0, go ahead and run this code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "import math\n",
    "# import pandas with alias pd\n",
    "import pandas as pd\n",
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellhead = pd.read_csv('http://aqueduct.isws.illinois.edu/data/381651_HRY-91C_hyd.csv')\n",
    "wellhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before plotting, let's talk a little about indices. These are effectively your row numbers, or at least, that's how this example starts out. The indices are the values in the first column, and can be used to help reference your data. You can also extract just the indices using `DataFrame.Index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#DataFrame.Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting with a Pandas DataFrame or Series can be done by simpling using `DataFrame['columnname'].plot()`. When plotting this way, Python knows to plot the index on the x-axis and all other columns on the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat. If you go to the original data, you will notice that this looks a lot like what is plotted. While a good start, we really want a useful x-axis. We don't really want to plot against the Index in this case, but rather the date and time. \n",
    "\n",
    "This short cut way of plotting with pandas (`DataFrame['columnname'].plot()`) is limiting, but we can try plotting like we did last week using matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code was slow doing it that way; something doesn't seem right here. Let's try the same thing, but using the index rather than TIMESTAMP, since we know that works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That worked, so we know we are doing some things correct, but Matplotlib is unhappy because the DateTime is a text string. Luckily, there is a little trick. Let's change the format of the date and time. Python/Pandas has a specific datatype for this called `Timestamp`. While this can get complicated to convert, this example is easy using the function `pd.to_datetime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the output is very similar to what we have already seen. Pretty boring, right? Well, before anything else, let's just try plotting again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, that was faster! You will also notice that the x-axis plots just years, but the values we fed in were years, months, day, hour, minutes, and seconds. How does Python/Pandas/Matplotlib know to do this? It is because our data is not a Timestamp object, and not a text string as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the type of the original TIMESTAMP\n",
    "wellhead = pd.read_csv('http://aqueduct.isws.illinois.edu/data/381651_HRY-91C_hyd.csv')\n",
    "print(wellhead['TIMESTAMP'][0])\n",
    "print(type(wellhead['TIMESTAMP'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the type of the converted TIMESTAMP to Timestamp\n",
    "wellhead['TIMESTAMP'] = pd.to_datetime(wellhead['TIMESTAMP'])\n",
    "print(wellhead['TIMESTAMP'][0])\n",
    "print(type(wellhead['TIMESTAMP'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will probably hear me slip up this semester and refer to the Timestamp object as a DateTime object; Timestamp is exclusive to Pandas but they are effectively the same thing. To read more, check out: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try it on your own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The well that we have been looking at, Henry 91C, is part of a monitoring network in the Green River Lowlands and is nested with a shallower well, Henry 91D. Go ahead and plot 91D up and compare with 91C. You can access the information here:\n",
    "\n",
    "https://www.isws.illinois.edu/groundwater-science/groundwater-monitoring-well-networks/green-river-lowlands-monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of your homework, you are going to need to investigate a few wells in the region and answer a few hydrogeologic questions. A good reference will be this report: https://www.ideals.illinois.edu/handle/2142/74884."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DateTimes'></a>\n",
    "\n",
    "\n",
    "\n",
    "# Module 2.2 More Fun with TimeStamps "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with Pandas, we often want to assign a specific column to serve as our index. It is particularly useful to assign the time column to the index, as you will soon see. There are multiple ways to do this, but perhaps the easiest is to assign the index during the import of an Excel spreadsheet.\n",
    "\n",
    "This is done by adding the argument `index_col = columnname` to the `pd.read_excel()` function.\n",
    "\n",
    "Before going any further, make sure to import packages again if you have taken a break before starting this module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "import math\n",
    "# import pandas with alias pd\n",
    "import pandas as pd\n",
    "# import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's also import our data again\n",
    "head_csv = 'http://aqueduct.isws.illinois.edu/data/381651_HRY-91C_hyd.csv'\n",
    "wellhead = pd.read_csv(head_csv)\n",
    "# good idea to rename the columns to make them either briefer or to eliminate the potentially confusing \"head\", which is a Pandas term\n",
    "wellhead = wellhead.rename(columns={\"RECORD\": \"record\", \"TIMESTAMP\": 'time', \"depth_to_water_from_land_surface\": \"dtw_ft\", \"head\": \"head_ft\"})\n",
    "wellhead.time = pd.to_datetime(wellhead.time)\n",
    "wellhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change index to time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot data using the shortcut in Pandas, or do it the classic way. Note that the two code blocks give the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a line at a time\n",
    "wellhead.head_ft.plot()\n",
    "plt.title('Henry 91C')\n",
    "plt.ylabel('head (ft)')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a line at a time\n",
    "plt.plot(wellhead.index,wellhead['head_ft'])\n",
    "plt.title('Henry 91C')\n",
    "plt.ylabel('head (ft)')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So what?\n",
    "\n",
    "Okay, swapping our timestamp/datetime to the index didn't gain us much for purposes of plotting. However, there is a powerful feature that we haven't discussed yet- sampling. Sometimes, you may not want to plot all data, but instead take an average over a period of time. This is called resampling or binning the data, and this can be done with the timestamp object with a single line of code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this code resamples the dataframe to an annual average water level\n",
    "wellhead_yr = wellhead.resample('Y').mean()\n",
    "print(wellhead_yr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean over a year (`Y`) was taken in every column, which isn't meaningful for the record (which was a unique id that has no physical meaning), but is very helpful for the head. Data can be resampled over other time intervals as well, including `D` for day, `W` for week, and `M` for month. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wellhead_yr['head_ft'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the highest water levels occurred in 2016 and 2019; the lowest occurred in 2014 and 2020. In your homework, you are going to compare this to precipitation data in each year. I don't know what this will actually show; it could be interesting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now try this on your own!\n",
    "\n",
    "Try plotting up the maximum and minimum elevations observed in each year at Henry 91C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this code resamples the dataframe to an annual average water level\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you surprised that the mean, max, and min all show different trends? I'll leave it to you to think about what these results mean, and also whether any of these years are misleading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Application'></a>\n",
    "\n",
    "# Module 2.3: Estimating Recharge\n",
    "\n",
    "After a precipitation event, a portion of the water vertically infiltrates to the aquifer, known as recharge. Recharge is measured in the same units as precipitation (length per time, commonly inches per year).  \n",
    "\n",
    "Employing hydrographs, we are going to use a simple hydrogeologic analysis known as the Water Table Fluctuation method. The concept is simple, changes in groundwater head <b>might</b> indicate a change in recharge, although other factors such as pumping or changes in stream levels could also be influencing this change. Let's not worry about that now.\n",
    "\n",
    "The idea is to apply transient mass balance concepts to estimate recharge as follows:\n",
    "\n",
    "$R=\\frac{\\Delta h S_y}{t}$\n",
    "\n",
    "where $R$ is recharge ($ft/d$), $\\Delta h$ is change in head ($ft$), $S_y$ is specific yield (unitless), and time is the interval over which the head change was observed ($d$). <b>Only positive recharge is generally considered</b>\n",
    "\n",
    "Let's see how this looks on a data set from the ISWS for a monitoring well in Mason County, resampled to capture the water level every week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.isws.illinois.edu/groundwater-science/groundwater-monitoring-well-networks/imperial-valley\n",
    "wellhead = pd.read_csv('http://aqueduct.isws.illinois.edu/data/360669.csv')\n",
    "wellhead.index = pd.to_datetime(wellhead['TIMESTAMP'])\n",
    "wellhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of notes on this. GWE is Groundwater Elevation, in feet above mean sea level. There is no depth to water, and the measurement method is included as well. You can see right away that the weekly measurements are originally taken by hand, but end with mostly transducer readings. The transducer (which measures water levels continuously) failed in late September of last year, but there is a hand measurement in December.\n",
    "\n",
    "When we do a weekly resampling, you will notice some major changes to the structure of this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wellhead_w = wellhead.resample('W').mean()\n",
    "print(wellhead_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a lot of NaN's. That simply represents weeks for which no data exists. However, we can still plot this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a line at a time\n",
    "wellhead_w.GWE.plot()\n",
    "plt.title('Wildlife Refuge Well')\n",
    "plt.ylabel('head (ft)')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a lot of missing data that will prove problematic here. Instead, let's just use the transducer data. This brings up a new important concept- how to trim a dataframe based on a certain condition. In this case, we want a new dataframe that only includes tranducer data. This is relatively easy to do, and the code takes the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.isws.illinois.edu/groundwater-science/groundwater-monitoring-well-networks/imperial-valley\n",
    "wellhead = pd.read_csv('http://aqueduct.isws.illinois.edu/data/360669.csv')\n",
    "wellhead.index = pd.to_datetime(wellhead['TIMESTAMP'])\n",
    "wellhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This syntax might take a little getting used to, but let's break it down. The code `wellhead['method']=='Transducer'` determines for each line in the dataframe where the relationship is true or false, and is accompanied by the index of the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellhead = pd.read_csv('http://aqueduct.isws.illinois.edu/data/360669.csv')\n",
    "wellhead.index = pd.to_datetime(wellhead['TIMESTAMP'])\n",
    "wellhead['method']=='Transducer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code takes this binary `True` and `False` output and selects from the dataframe only those lines where the condition is true. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellhead[wellhead['method']=='Transducer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we could create a dataframe where elevations are only greater than 476 ft using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been experimenting a lot with this dataframe, so just to make sure, let's re-run our code in a single block, from importing data to resampling weekly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellhead = pd.read_csv('http://aqueduct.isws.illinois.edu/data/360669.csv')\n",
    "wellhead.index = pd.to_datetime(wellhead['TIMESTAMP'])\n",
    "wellhead = wellhead[wellhead['method']=='Transducer']\n",
    "wellhead_w = wellhead.resample('W').mean()\n",
    "wellhead_w.GWE.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $\\Delta h$\n",
    "\n",
    "Now let's calculate the head differences between points in time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to calculate the difference in the average heads over each weekly interval. To do this, we simply take the difference between the head and the shifted head using the function `shift()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, I intentionally tackled a few steps there, but we need to walk through that again. What is shift doing here? Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the original data\n",
    "wellhead_w['GWE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the shifted data\n",
    "wellhead_w['GWE'].shift()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index does not change, nor does the length. However, the first value has been pushed down by one, replaced with an NaN. NaN's are just Pandas/Pythons way of defining \"Not a Number\", we'll take care of that next. \n",
    "\n",
    "What are we really doing by shifting values? Well, if we subtract the two columns from one another, we are really taking the difference from the head in the previous day (given by the shifted value) and the head in the current day (given by the unshifted value). In other words, the difference on `2016-09-04` between the two is 475.76 (the actual head on that day) minus 475.81 (the head on the previous day). The head went down in this case, so the negative sign that is yielded by the difference makes sense.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrolling back up, you can see that the value calculated as `delta h` for the first time interval is an `NaN`. Math is complicated when NaNs are present, as happens in the first delta_h. Let's fill that value with a float in by backfilling values (NaNs are set equal to the next value). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wellhead_w = wellhead_w.fillna(method='bfill')\n",
    "print(wellhead_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate recharge\n",
    "Recall that our goal is to calculate recharge usig the Water Table Fluctuation method, which requires specific yield $S_y$ and time interval $\\Delta t$. For simplicity, let's assume that $S_y$ is equal to 0.2 (we will see later if this actually makes sense) and a time interval of 7 days (consistent with our resampling of 1 week)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sy = 0.2\n",
    "timeint = 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So close, but there are a lot of negative recharge values here. The Water Table Fluctation method as defined by the USGS as only positive recharge values, negative values should be set to 0 recharge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a nifty little code that does this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a code that sets negative values equal to zero\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot head and recharge data\n",
    "\n",
    "We want to observe the relationship between head changes and recharge. Let's plot both up. Note that we add a title based on the original url. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a line at a time\n",
    "wellhead.GWE.plot()\n",
    "plt.title(\"Head: \"+ head_csv[39:])\n",
    "plt.ylabel('head (ft)')\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Head: \"+ head_csv[39:])\n",
    "wellhead_w.recharge.plot()\n",
    "plt.ylabel('recharge (ft/day)')\n",
    "plt.xticks(rotation = 30)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plots are difficult to compare because the curves aren't on the same line. Using a slightly more complicated code, we can plot both heads and recharge on the same plot using different y-axes. \n",
    "\n",
    "I'll post a supplemental video discussing the details of this code. For now, you should be able to copy, paste, and modify. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a figure the primary axis\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "# There are a different set of functions/methods for defining properties of the primary axis. \n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Head (ft)', color=color)\n",
    "ax1.plot(wellhead.GWE, color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.tick_params(axis='x', rotation=30)\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Recharge (ft/day)', color=color)  # we already handled the x-label with ax1\n",
    "ax2.plot(wellhead_w.recharge, color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.axhline(linewidth=2, color='k')\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You now have everything you need to start on Module 2's Homework assignment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
